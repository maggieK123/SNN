{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad1bc151-dcd3-41c4-8e90-b6e1acae679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, sampler\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec82d333-6e74-4176-9083-f0cc4894af5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PseudoSpikeRect(torch.autograd.Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, input, vth, grad_win, grad_amp):\n",
    "    \n",
    "        ctx.save_for_backward(input)\n",
    "        ctx.vth = vth\n",
    "        ctx.grad_win = grad_win\n",
    "        ctx.grad_amp = grad_amp\n",
    "        output = input.gt(vth).float()\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \n",
    "        input, = ctx.saved_tensors\n",
    "        vth = ctx.vth\n",
    "        grad_win = ctx.grad_win\n",
    "        grad_amp = ctx.grad_amp\n",
    "        grad_input = grad_output.clone()\n",
    "        spike_pseudo_grad = torch.abs((input-vth))<grad_win\n",
    "        grad = grad_amp * grad_input * spike_pseudo_grad.float()\n",
    "        return grad, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4a89793-bb24-4474-8520-d6defdd72467",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearIFCell(nn.Module):\n",
    "    \"\"\" Leaky Integrate-and-fire neuron layer\"\"\"\n",
    "\n",
    "    def __init__(self, psp_func, pseudo_grad_ops, param):\n",
    "\n",
    "        super(LinearIFCell, self).__init__()\n",
    "        self.psp_func = psp_func\n",
    "        self.pseudo_grad_ops = pseudo_grad_ops\n",
    "        self.vdecay, self.vth, self.grad_win, self.grad_amp = param\n",
    "\n",
    "    def forward(self, input_data, state):\n",
    "        \n",
    "        pre_spike, pre_volt = state\n",
    "        volt = self.vdecay  * pre_volt * (1. - pre_spike) + self.psp_func(input_data)\n",
    "        output = self.pseudo_grad_ops(volt,self.vth, self.grad_win, self.grad_amp)\n",
    "        return output, (output, volt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6f90a23-edc4-49b8-be30-5160d2925093",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleHiddenLayerSNN(nn.Module):\n",
    "    \"\"\" SNN with single hidden layer \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim, param_dict):\n",
    "        \n",
    "        super(SingleHiddenLayerSNN, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        pseudo_grad_ops = PseudoSpikeRect.apply\n",
    "        self.hidden_cell = LinearIFCell(nn.Linear(input_dim,hidden_dim,bias=False),pseudo_grad_ops,param_dict['hid_layer'])\n",
    "        self.output_cell = LinearIFCell(nn.Linear(hidden_dim,output_dim,bias=False),pseudo_grad_ops,param_dict['out_layer'])\n",
    "        \n",
    "\n",
    "    def forward(self, spike_data, init_states_dict, batch_size, spike_ts):\n",
    "        \n",
    "        hidden_state, out_state = init_states_dict['hid_layer'], init_states_dict['out_layer']\n",
    "        spike_data_flatten = spike_data.view(batch_size, self.input_dim, spike_ts)\n",
    "        output_list = [] #List to store the output at each timestep\n",
    "        for tt in range(spike_ts):\n",
    "            \n",
    "            input_data = spike_data_flatten[:,:,tt]\n",
    "            hidden_layer, hidden_state= self.hidden_cell(input_data,hidden_state)#forward\n",
    "            output_layer,out_state = self.output_cell(hidden_layer,out_state)\n",
    "            output_list.append(output_layer)\n",
    "        \n",
    "        output = torch.stack(output_list)\n",
    "        \n",
    "        output= torch.sum(output, dim = 0)\n",
    "       \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cdf4c3f-23e7-4f1d-8f4e-2c1702950ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrapSNN(nn.Module):\n",
    "    \"\"\" Wrapper of SNN \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim, param_dict, device):\n",
    "        \n",
    "        super(WrapSNN, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.device = device\n",
    "        self.snn = SingleHiddenLayerSNN(input_dim, output_dim, hidden_dim, param_dict)\n",
    "\n",
    "    def forward(self, spike_data):\n",
    "        \n",
    "        batch_size = spike_data.shape[0]\n",
    "        spike_ts = spike_data.shape[-1]\n",
    "        init_states_dict = {}\n",
    "        hidden_volt = torch.zeros(batch_size, self.hidden_dim, device=self.device)\n",
    "        hidden_spike = torch.zeros(batch_size, self.hidden_dim, device=self.device)\n",
    "        init_states_dict['hid_layer'] = (hidden_spike, hidden_volt)\n",
    "        out_volt = torch.zeros(batch_size, self.output_dim, device=self.device)\n",
    "        out_spike = torch.zeros(batch_size, self.output_dim, device=self.device)\n",
    "        init_states_dict['out_layer'] = (out_spike, out_volt)\n",
    "        output = self.snn(spike_data, init_states_dict, batch_size, spike_ts)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebaa1dd8-6482-4baf-8215-2b1b392830c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_2_event_img(image, device, spike_ts):\n",
    "    \n",
    "    batch_size = image.shape[0]\n",
    "    channel_size = image.shape[1]\n",
    "    image_size = image.shape[2]\n",
    "    image = image.view(batch_size, channel_size, image_size, image_size, 1)\n",
    "    random_image = torch.rand(batch_size,channel_size,image_size,image_size,spike_ts)\n",
    "    random_image.to(device)\n",
    "    event_image = torch.gt(image,random_image).float()\n",
    "\n",
    "    return event_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e145211e-3e76-4bd3-a3ef-14ab871ca453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stbp_snn_training(network, spike_ts, device, batch_size=128, test_batch_size=256, epoch=100):\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(\"./data\")\n",
    "        print(\"Directory data Created\")\n",
    "    except FileExistsError:\n",
    "        print(\"Directory data already exists\")\n",
    "    \n",
    "    data_path = './data/'\n",
    "    train_dataset = torchvision.datasets.MNIST(root=data_path, train=True, download=True,\n",
    "                                               transform=transforms.ToTensor())\n",
    "    test_dataset = torchvision.datasets.MNIST(root=data_path, train=False, download=True,\n",
    "                                              transform=transforms.ToTensor())\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                  shuffle=False, num_workers=4)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=test_batch_size,\n",
    "                                 shuffle=False, num_workers=4)\n",
    "\n",
    "                                              \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(network.parameters(), lr=0.001, momentum=0.9)#was .01\n",
    "    \n",
    "    train_loss_list, test_accuracy_list = [], []\n",
    "    test_num = len(test_dataset)\n",
    "    network.to(device)\n",
    "    \n",
    "    \n",
    "    for ee in range(epoch):\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        running_batch_num = 0\n",
    "        train_start = time.time()\n",
    "        \n",
    "        \n",
    "        for data in train_dataloader:\n",
    "            \n",
    "            image = data[0]\n",
    "            label = data[1]\n",
    "            image= image.to(device)\n",
    "            label= label.to(device)\n",
    "            event_image = img_2_event_img(image, device, spike_ts)\n",
    "            optimizer.zero_grad()\n",
    "            input = network.forward(event_image)\n",
    "            loss = criterion(input, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            running_batch_num += 1\n",
    "        train_end = time.time()\n",
    "        train_loss_list.append(running_loss / running_batch_num)\n",
    "        print(\"Epoch %d Training Loss %.4f\" % (ee, train_loss_list[-1]), end=\" \")\n",
    "        test_correct_num = 0\n",
    "        test_start = time.time()\n",
    "        with torch.no_grad():\n",
    "            for data in test_dataloader:\n",
    "                image = data[0]\n",
    "                label = data[1]\n",
    "                image.to(device)\n",
    "                label.to(device)\n",
    "                event_image = img_2_event_img(image, device, spike_ts)\n",
    "                outputs = network.forward(event_image)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                test_correct_num+= ((predicted==label).sum().to(\"cpu\")).item()\n",
    "        \n",
    "        \n",
    "        test_end = time.time()\n",
    "        test_accuracy_list.append(test_correct_num / test_num)\n",
    "        print(\"Test Accuracy %.4f Training Time: %.1f Test Time: %.1f\" % (\n",
    "            test_accuracy_list[-1], train_end - train_start, test_end - test_start))\n",
    "    \n",
    "   \n",
    "    print(\"End Training\")\n",
    "    network.to('cpu')\n",
    "    return train_loss_list, test_accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e751bb6c-e711-423a-a04c-7d6ef53d3eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory data already exists\n",
      "Epoch 0 Training Loss 1.5788 Test Accuracy 0.7019 Training Time: 10.1 Test Time: 4.1\n",
      "Epoch 1 Training Loss 1.0729 Test Accuracy 0.7323 Training Time: 10.0 Test Time: 4.2\n",
      "Epoch 2 Training Loss 0.9869 Test Accuracy 0.7910 Training Time: 10.2 Test Time: 4.5\n",
      "Epoch 3 Training Loss 0.8592 Test Accuracy 0.8769 Training Time: 10.4 Test Time: 4.7\n",
      "Epoch 4 Training Loss 0.7004 Test Accuracy 0.8913 Training Time: 10.6 Test Time: 4.2\n",
      "End Training\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_dim = 784\n",
    "output_dim = 10\n",
    "hidden_dim = 256\n",
    "param_dict = {'hid_layer': [.5, .4, .2, 1],'out_layer': [.5, .4, .2, 1]}\n",
    "spike_ts = 3\n",
    "snn = WrapSNN(input_dim, output_dim, hidden_dim, param_dict, device)\n",
    "batch_size=128\n",
    "test_batch_size=256\n",
    "epoch=5\n",
    "train_loss_list, test_accuracy_list = stbp_snn_training(snn, spike_ts, device, batch_size=128, test_batch_size=256, epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54beca98-772c-4abb-9743-bfdbc1687ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
